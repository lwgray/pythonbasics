{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tour de Python Level 2 ●○○○\n",
    "\n",
    "* Python `stdlib`\n",
    "* `import` syntax\n",
    "* Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## built-in Python\n",
    "\n",
    "* Everything we've talked about so far is referred to as part of the Python \"built-in\"s\n",
    "* Every Python session has access to everything we've learned no matter what\n",
    "* The built-ins are general purpose building blocks: \"primitive\" data types (like strings, integers, dictionaries), control flow statements, basic operators, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## moving on (briefly) to the Python `stdlib`\n",
    "\n",
    "* every Python installation also comes with special data types, operators, functions, and methods to address specific types of problems\n",
    "    * ex. `datetime` for storing time data that are cognizant of year/month/day/timezone\n",
    "* by default these are not loaded into each Python session, but instead have to be **imported**\n",
    "* `stdlib` = \"standard library\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Python modules\n",
    "\n",
    "* any `.py` file can also be referred to as a \"Python module\"\n",
    "* modules can be imported using one of four styles of import syntax. here's one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* the list of modules already accessible to any vanilla Python installation because they are in the `stdlib` are listed online at https://docs.python.org/3/library/ ⇢\n",
    "* importing a module makes its code definitions accessible in whatever environment they are being imported to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Variants of import syntax and namespaces\n",
    "\n",
    "* Python provides 3 styles of import syntax that affect the namespacing of the imported module and its members\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "math.ceil(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of import syntax 1\n",
    "\n",
    "<p><b>if import syntax is:</b></p>\n",
    "<p><font color=green>import</font> <font color=orange>module_name</font></p>\n",
    "\n",
    "<p><b>then call syntax is:</b></p>\n",
    "<p><font color=orange>module_name</font>.<font color=blue>member_name</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import math as m\n",
    "m.ceil(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of import syntax 2\n",
    "\n",
    "<p><b>if import syntax is:</b></p>\n",
    "<p><font color=green>import</font> <font color=orange>module_name</font> <font color=green>as</font> <font color=goldenrod>alias</font></p>\n",
    "\n",
    "<p><b>then call syntax is:</b></p>\n",
    "<p><font color=goldenrod>alias</font>.<font color=blue>member_name</font></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "ceil(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of import syntax 3\n",
    "\n",
    "<p><b>if import syntax is:</b></p>\n",
    "<p><font color=green>from</font> <font color=orange>module_name</font> <font color=green>import</font> <font color=blue>member_name</font>, <font color=grey>...</font></p>\n",
    "\n",
    "<p><b>then call syntax is:</b></p>\n",
    "<p><font color=blue>member_name</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `stdlib` greatest hits\n",
    "\n",
    "* `datetime`\n",
    "* `random.seed`, `random.random`\n",
    "* `os.path.exists`, `os.path.join`, `os.path.abspath`\n",
    "* `csv.reader`, `csv.DictReader`\n",
    "* `csv.writer`\n",
    "* `json.loads`, `json.dumps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Get your feet wet\n",
    "\n",
    "In the Python interpreter, try using the 3 different styles of import syntax to import the following **functions**, and call them properly based on the type of import syntax you used. You will need to exit and re-enter your python session to clear your prior import syntax each time.\n",
    "\n",
    "* `random.random`\n",
    "* `os.getcwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Going past the `stdlib`\n",
    "\n",
    "* remember: the `stdlib` is maintained by the Python Software Foundation and comes with every installation of Python\n",
    "* other members of the Python community write their own extensions to the Python built-ins called **packages**\n",
    "    * usually they are even more specialized than modules in the `stdlib`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introducing our data analysis packages\n",
    "\n",
    "* **Pandas**\n",
    "   * used for processing tabular data\n",
    "   * core data type is the `DataFrame`\n",
    "   * port of R's DataFrame paradigm\n",
    "* **Matplotlib**\n",
    "   * used to generate charts such as histograms or box plots from Python data structures\n",
    "   * port of MATLAB's charting functionalilty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ~~Installing~~ python packages\n",
    "\n",
    "* lucky you - you don't have to! For this class, since we used the Anaconda distribution of Python, the python packages we want to use are already installed!\n",
    "    * the full list for your installation can be found at https://docs.anaconda.com/anaconda/packages/pkg-docs ⇢\n",
    "* more generally: there are many ways to find and download community-supported Python extensions, but the most popular way is via a *package manager* that downloads from PyPI at https://pypi.python.org/pypi ⇢\n",
    "    * popular *package managers* include `pip`, `pipenv`, and `conda`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Tour de Python Level 2 ○●○○\n",
    "\n",
    "* `DataFrame`\n",
    "* `Series`\n",
    "* Python attributes\n",
    "* `DataFrame` indexing\n",
    "* Querying `DataFrame`s with boolean series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## The `pandas` dataframe\n",
    "\n",
    "* a two dimensional data structure representing tabular data\n",
    "* has *columns* and *rows*\n",
    "* each column's data is of the same *data type*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating a pandas dataframe\n",
    "\n",
    "* use a convenience function against a file on disk\n",
    "    * [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html), for CSV data\n",
    "    * [`pd.read_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html), for general reading of tabular data, including `.tsv` files\n",
    "    * [`pd.read_json`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html) for JSON data\n",
    "    * [`pd.read_excel`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html) for Excel files, particularly useful for excel files with many sheets\n",
    "    * [`pd.read_html`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html) for reading HTML `<table>`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of a pandas dataframe convenience function\n",
    "\n",
    "<p><font color=blue>variable_name</font> = <font color=green>pd</font>.<font color=goldenrod>convenience_method</font>(<font color=red>path_as_a_string</font>)</p>\n",
    "<ul><li> <font color=goldenrod>read_csv</font></li>\n",
    " <li><font color=goldenrod>read_table</font></li>\n",
    " <li><font color=goldenrod>read_json</font></li>\n",
    " <li><font color=goldenrod>read_excel</font></li>\n",
    " <li><font color=goldenrod>read_html</font></ul>\n",
    " \n",
    " PS: Of course, remember that the path can be an absolute or relative path!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Creating a pandas dataframe inline\n",
    "\n",
    "* instantiate a `dataframe` instance directly, passing it a `data` parameter with something that can be cast into a dataframe shape\n",
    "* the general format for something that can be cast to a dataframe shape takes a form like: `[[row],[row],[row]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_direct = pd.DataFrame(data=[[\"a\", 1, 5.0], [\"b\", 2, 10.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of instantiating a DataFrame directly\n",
    "\n",
    "<p><font color=blue>variable_name</font> = <font color=green>pd</font>.<font color=green>DataFrame</font>(data=<font color=red>data_castable_to_dataframe</font>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_direct_with_columns = pd.DataFrame(data=[[\"a\", 1, 5.0], [\"b\", 2, 10.0]],\n",
    "                                     columns=[\"letter\", \"integer\", \"float\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_direct_with_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of instantiating a DataFrame directly\n",
    "\n",
    "<p><font color=blue>variable_name</font> = <font color=green>pd</font>.<font color=green>DataFrame</font>(data=<font color=red>data_castable_to_dataframe</font>, columns=<font color=purple>list_of_column_names</font>)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Python attributes\n",
    "\n",
    "* instances of more complex data types have **attributes** associated with them\n",
    "* they are accessible using the dot notation like `variable_name.attribute_name`\n",
    "* these are not callable - in practical terms to us at this point, this means they don't need the parentheses `()` after them - and simply `return` the static data that attribute refers to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## DataFrame attributes\n",
    "\n",
    "* `DataFrame`s are one case of a data type that has attributes associated with them\n",
    "* three interesting ones for us are \n",
    "    * `DataFrame.columns`\n",
    "    * `DataFrame.shape`\n",
    "    * `DataFrame.values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Series\n",
    "\n",
    "The other important data type in the `pandas` package is that of a \n",
    " [`<class 'pandas.core.series.Series>`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html), which is effectively the one-dimensional representation of a DataFrame axis - for example one row, or one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sepal_length = df['Sepal Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(sepal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sepal_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Series attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sepal_length.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sepal_length.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sepal_length.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing a DataFrame\n",
    "\n",
    "Index notation like we are used to with one-dimensions data structures like lists and dictionaries is modified a bit for two-dimensional DataFrames.\n",
    "\n",
    "To illuminate series, we already saw the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sepal_length = df['Sepal Length']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of basic indexing for columns\n",
    "\n",
    "<p><font color=blue>variable_name</font>[<font color=red>column_label</font>]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of one-dimensional iloc indexing for rows\n",
    "\n",
    "<p><font color=blue>variable_name</font>.<font color=green>iloc</font>[<font color=red>row_index</font>]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.iloc[1,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of two-dimensional iloc indexing for cells\n",
    "\n",
    "<p><font color=blue>variable_name</font>.<font color=green>iloc</font>[<font color=red>row_index</font>,<font color=red>column_index</font>]</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[1,'Sepal Width']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of one- and two-dimensional `loc` indexing \n",
    "\n",
    "<p><font color=blue>variable_name</font>.<font color=green>loc</font>[<font color=red>row_label</font>]</p>\n",
    "\n",
    "<p><font color=blue>variable_name</font>.<font color=green>loc</font>[<font color=red>row_label</font>,<font color=red>column_label</font>]</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic querying with a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# you can use expressions to slice and dice using logic\n",
    "print(df[df['Sepal Length'] == 6.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# how does this work? by supplying to the index a boolean array\n",
    "boolean_series = df['Sepal Length'] == 6.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "boolean_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this can get quite complex\n",
    "df[(df['Sepal Length']==6.9) & (df['Species']=='versicolor')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anatomy of boolean array indexing\n",
    "\n",
    "<p><font color=bulue>variable_name</font>[<font color=red>series_wise_boolean_expression</font>]</p>\n",
    "\n",
    "Use `&` and `|` to represent `and` and `or`, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grouping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "groups = df.groupby(\"Species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for key, group in groups:\n",
    "    print(key)\n",
    "    print(group.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This gives you a convenient way to apply logic based on a group filter\n",
    "# For example, use the DataFrame.describe method to easily get summary statistics on each species group\n",
    "for key, group in groups:\n",
    "    print(key)\n",
    "    print(group.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# You can chain an aggregation onto a groupby to get groupwise stats outside of what is in `describe`\n",
    "print(df.groupby(\"Species\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(df.groupby(\"Species\").max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(df.groupby(\"Species\").min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get your feet wet\n",
    "\n",
    "Choose any of the data sets I've provided in Canvas to begin practicing with these first 5 pandas tasks.\n",
    "\n",
    "Try to:\n",
    "\n",
    "1. Load the data as a pandas DataFrame.\n",
    "    * HINT: Use a convenience method to pull the data into a DataFrame from a file path!\n",
    "2. Describe the data in the DataFrame using the describe() method.\n",
    "3. Select just row 5 from the DataFrame. Now how about the value from row 5, column 2. How about selecting a whole column by its label?\n",
    "4. Use the groupby() method against a categorial column in your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tour de Python Level 2 ○○●○\n",
    "\n",
    "* `pandas` based processing techniques for\n",
    "    * dealing with duplicates\n",
    "    * dealing with sparse data\n",
    "    * applying custom logic\n",
    "    * quick vis with just pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dropped_df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dropped_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dealing with sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sparse_df = pd.read_csv(\"hepatitis.csv\", na_values=\"?\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sparse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sparse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sparse_df.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sparse_df.fillna(1000).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sparse_df.interpolate().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applying custom logic cellwise\n",
    "\n",
    "> > Write a program that prints the numbers from 1 to 100. But for multiples of three print “Fizz” instead of the number and for the multiples of five print “Buzz”. For numbers which are multiples of both three and five print “FizzBuzz”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=['A','B','C','D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def fizz_buzz_ify(cell):\n",
    "    cell = float(cell)\n",
    "    if (cell % 3.0 == 0) & (cell % 5.0 == 0):\n",
    "        return \"FizzBuzz\"\n",
    "    elif cell % 3.0 == 0:\n",
    "        return \"Fizz\"\n",
    "    elif cell % 5.0 == 0:\n",
    "        return \"Buzz\"\n",
    "    else:\n",
    "        return cell\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "num_df.applymap(fizz_buzz_ify).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick vis with just pandas\n",
    "\n",
    "Pandas also includes some built-in visualization methods against dataframes for common plots. It is as simple as calling the `hist()` or `plot()` method on a dataframe to get a visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.plot('Sepal Length', 'Sepal Width', kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[df['Species'] == 'virginica'].hist(column=['Sepal Width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Using the `chipotle.tsv` file from class folder, answer the following questions. (HINT: What convenience method works on `.tsv`s?)\n",
    "\n",
    "1. What is the number of observations in this dataset?\n",
    "    - HINT: (1) and (2) can be answered with the same DataFrame attribute!\n",
    "2. What is the number of columns in the dataset?\n",
    "3. What are the names of all the columns of this dataset?\n",
    "4. What was the most ordered item?\n",
    "   - HINT: Consider a groupby with an aggregation!\n",
    "   - HINT: You will need to add up the `quantity` field across items of the same `item_name` and look at the results. There is an aggregation method called `sum()`.\n",
    "5. How many times was a Veggie Salad Bowl ordered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Tour de Python Level 2 ○○○●\n",
    "\n",
    "* basic `Matplotlib`\n",
    "* a realistic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['Sepal Width'], df['Sepal Length'])\n",
    "plt.xlabel('Sepal Width')\n",
    "plt.ylabel('Sepal Length')\n",
    "plt.title('Sepal Width vs Sepal Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A more realistic example\n",
    "\n",
    "Take a look at the file `\"gdp_time_series\"` in your terminal with `cat`. You'll notice it's not so well formatted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('gdp_time_series', skiprows=3, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(df['YEAR'],df['AUSTRIA'])\n",
    "plt.ylabel('Per Capita Annual GDP')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
